{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.How does regularization (L1 and L2) help in preventing overfitting?"
      ],
      "metadata": {
        "id": "AfJ5FZkyPJdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.L1 Regularization: Adds a penalty based on the absolute values of the model's\n",
        "coefficients. This can shrink some coefficients all the way to zero, effectively removing less important features from the model. It's like picking only the most helpful tools for the job.\n",
        "\n",
        "2.L2 Regularization: Adds a penalty based on the square of the coefficients. This keeps the coefficients small and balances the importance of all features, making the model more general and less likely to overfit."
      ],
      "metadata": {
        "id": "xa9qmpCnOxrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Why is feature scaling important in gradient descent?\n",
        "\n",
        "\n",
        "Feature scaling ensures that all features contribute equally to the loss function during optimization."
      ],
      "metadata": {
        "id": "eAfPii-mPQS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem-Solving\n",
        "1. Given a dataset with missing values, how would you handle them before training an ML model?\n",
        "\n",
        "\n",
        "Drop missing values:\n",
        "\n",
        "If a feature or row has too many missing values and isn't crucial for the analysis, it's often best to remove it entirely. This prevents the incomplete data from distorting the model.\n",
        "\n",
        "Fill in missing values:\n",
        "\n",
        "For numbers, you can use simple replacements like the average (mean), middle value (median), or the most common value (mode).\n",
        "For categories, you can fill in with the most frequent category"
      ],
      "metadata": {
        "id": "7AicKocCPQGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Design a pipeline for building a classification model. Include steps for data preprocessing.\n",
        "\n",
        "Data Preprocessing:\n",
        "\n",
        "1.Handle missing values.\n",
        "\n",
        "2.Encode categorical variables\n",
        "\n",
        "3.Scale/normalize numerical features.\n",
        "\n",
        "4.Perform feature selection or dimensionality reduction\n",
        "\n",
        "5.Split data into training and testing sets.\n",
        "\n",
        "\n",
        "Model Building:\n",
        "\n",
        "1.Select a classification algorithm\n",
        "\n",
        "2.Train the model on the training set.\n",
        "\n",
        "\n",
        "Model Evaluation:\n",
        "\n",
        "1.Validate with cross-validation.\n",
        "\n",
        "2.Assess performance using metrics like accuracy, precision, recall, F1-score, or ROC-AUC.\n",
        "\n",
        "\n",
        "Hyperparameter Tuning:\n",
        "Use grid search or random search.\n",
        "\n",
        "\n",
        "Deploy"
      ],
      "metadata": {
        "id": "XUzZ5U9kPP1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coding\n",
        "1. Write a Python script to implement a decision tree classifier using Scikit-learn."
      ],
      "metadata": {
        "id": "2Ga7UWwbQ6ky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A5wjPEvOSFf",
        "outputId": "d18f5805-9a6c-406c-fefd-35a08cd44441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Given a dataset, write code to split the data into training and testing sets using an 80-20 split."
      ],
      "metadata": {
        "id": "yNhC12sbRT7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "AIOG8HSCRJzk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case Study\n",
        "\n",
        "A company wants to predict employee attrition. What kind of ML problem is this? Which algorithms would you choose and why?"
      ],
      "metadata": {
        "id": "nStkTdJHRhEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a binary classification problem.\n",
        "\n",
        "I would choose Logistic Regression or SVM or Random Forest because Employee attrition often depends on complex, non-linear relationships among features.\n",
        "Logistic Regression can act as a baseline model due to its simplicity and interpretability."
      ],
      "metadata": {
        "id": "D38iej-0Rl48"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnCPSG5oRcli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}